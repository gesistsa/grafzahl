<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Supervised Machine Learning for Textual Data Using Transformers and Quanteda • grafzahl</title>
<script src="deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="deps/JetBrains_Mono-0.4.9/font.css" rel="stylesheet">
<link href="deps/Roboto_Slab-0.4.9/font.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/all.min.css" rel="stylesheet">
<link href="deps/font-awesome-6.5.2/css/v4-shims.min.css" rel="stylesheet">
<script src="deps/headroom-0.11.0/headroom.min.js"></script><script src="deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="deps/search-1.0.0/fuse.min.js"></script><script src="deps/search-1.0.0/mark.min.js"></script><!-- pkgdown --><script src="pkgdown.js"></script><meta property="og:title" content="Supervised Machine Learning for Textual Data Using Transformers and Quanteda">
<meta name="description" content="Duct tape the quanteda ecosystem (Benoit et al., 2018) &lt;doi:10.21105/joss.00774&gt; to modern Transformer-based text classification models (Wolf et al., 2020) &lt;doi:10.18653/v1/2020.emnlp-demos.6&gt;, in order to facilitate supervised machine learning for textual data. This package mimics the behaviors of quanteda.textmodels and provides a function to setup the Python environment to use the pretrained models from Hugging Face &lt;https://huggingface.co/&gt;. More information: &lt;doi:10.5117/CCR2023.1.003.CHAN&gt;.">
<meta property="og:description" content="Duct tape the quanteda ecosystem (Benoit et al., 2018) &lt;doi:10.21105/joss.00774&gt; to modern Transformer-based text classification models (Wolf et al., 2020) &lt;doi:10.18653/v1/2020.emnlp-demos.6&gt;, in order to facilitate supervised machine learning for textual data. This package mimics the behaviors of quanteda.textmodels and provides a function to setup the Python environment to use the pretrained models from Hugging Face &lt;https://huggingface.co/&gt;. More information: &lt;doi:10.5117/CCR2023.1.003.CHAN&gt;.">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top bg-light" data-bs-theme="light" aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="index.html">grafzahl</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.11</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="articles/grafzahl.html">Get started</a></li>
<li class="nav-item"><a class="nav-link" href="reference/index.html">Reference</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/gesistsa/grafzahl/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
      </ul>
</div>


  </div>
</nav><div class="container template-home">
<div class="row">
  <main id="main" class="col-md-9"><div class="section level1">
<div class="page-header"><h1 id="grafzahl-">grafzahl <img src="reference/figures/grafzahl_logo.png" align="right" height="139"><a class="anchor" aria-label="anchor" href="#grafzahl-"></a>
</h1></div>
<!-- badges: start -->

<p>The goal of grafzahl (<strong>G</strong>racious <strong>R</strong> <strong>A</strong>nalytical <strong>F</strong>ramework for <strong>Z</strong>appy <strong>A</strong>nalysis of <strong>H</strong>uman <strong>L</strong>anguages [1]) is to duct tape the <a href="https://github.com/quanteda/quanteda" class="external-link">quanteda</a> ecosystem to modern <a href="https://simpletransformers.ai/" class="external-link">Transformer-based text classification models</a>, e.g. BERT, RoBERTa, etc. The model object looks and feels like the textmodel S3 object from the package <a href="https://github.com/quanteda/quanteda.textmodels" class="external-link">quanteda.textmodels</a>.</p>
<p>If you don’t know what I am talking about, don’t worry, this package is gracious. You don’t need to know a lot about Transformers to use this package. See the examples below.</p>
<p>Please cite this software as:</p>
<p>Chan, C., (2023). <a href="paper/grafzahl_sp.pdf">grafzahl: fine-tuning Transformers for text data from within R</a>. <em>Computational Communication Research</em> 5(1): 76-84. <a href="https://doi.org/10.5117/CCR2023.1.003.CHAN" class="external-link uri">https://doi.org/10.5117/CCR2023.1.003.CHAN</a></p>
<div class="section level2">
<h2 id="installation-local-environment">Installation: Local environment<a class="anchor" aria-label="anchor" href="#installation-local-environment"></a>
</h2>
<p>Install the CRAN version</p>
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"grafzahl"</span><span class="op">)</span></span></code></pre></div>
<p>After that, you need to setup your conda environment</p>
<div class="sourceCode" id="cb2"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://gesistsa.github.io/grafzahl/">grafzahl</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="reference/setup_grafzahl.html">setup_grafzahl</a></span><span class="op">(</span>cuda <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="co">## if you have GPU(s)</span></span></code></pre></div>
</div>
<div class="section level2">
<h2 id="on-remote-environments-eg-google-colab">On remote environments, e.g. Google Colab<a class="anchor" aria-label="anchor" href="#on-remote-environments-eg-google-colab"></a>
</h2>
<p>On Google Colab, you need to enable non-Conda mode</p>
<div class="sourceCode" id="cb3"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/install.packages.html" class="external-link">install.packages</a></span><span class="op">(</span><span class="st">"grafzahl"</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">require</a></span><span class="op">(</span><span class="va"><a href="https://gesistsa.github.io/grafzahl/">grafzahl</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="reference/use_nonconda.html">use_nonconda</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<p>Please refer the vignette.</p>
</div>
<div class="section level2">
<h2 id="usage">Usage<a class="anchor" aria-label="anchor" href="#usage"></a>
</h2>
<p>Suppose you have a bunch of tweets in the quanteda corpus format. And the corpus has exactly one docvar that denotes the labels you want to predict. The data is from <a href="https://github.com/pablobarbera/incivility-sage-open" class="external-link">this repository</a> (Theocharis et al., 2020).</p>
<div class="sourceCode" id="cb4"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">unciviltweets</span></span>
<span><span class="co">#&gt; Corpus consisting of 19,982 documents and 1 docvar.</span></span>
<span><span class="co">#&gt; text1 :</span></span>
<span><span class="co">#&gt; "@ @ Karma gave you a second chance yesterday.  Start doing m..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; text2 :</span></span>
<span><span class="co">#&gt; "@ With people like you, Steve King there's still hope for we..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; text3 :</span></span>
<span><span class="co">#&gt; "@ @ You bill is a joke and will sink the GOP. #WEDESERVEBETT..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; text4 :</span></span>
<span><span class="co">#&gt; "@ Dream on. The only thing trump understands is how to enric..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; text5 :</span></span>
<span><span class="co">#&gt; "@ @ Just like the Democrat taliban party was up front with t..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; text6 :</span></span>
<span><span class="co">#&gt; "@ you are going to have more of the same with HRC, and you a..."</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; [ reached max_ndoc ... 19,976 more documents ]</span></span></code></pre></div>
<p>In order to train a Transfomer model, please select the <code>model_name</code> from <a href="https://huggingface.co/models" class="external-link">Hugging Face’s list</a>. The table below lists some common choices. In most of the time, providing <code>model_name</code> is sufficient, there is no need to provide <code>model_type</code>.</p>
<p>Suppose you want to train a Transformer model using “bertweet” (Nguyen et al., 2020) because it matches your domain of usage. By default, it will save the model in the <code>output</code> directory of the current directory. You can change it to elsewhere using the <code>output_dir</code> parameter.</p>
<div class="sourceCode" id="cb5"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="reference/grafzahl.html">grafzahl</a></span><span class="op">(</span><span class="va">unciviltweets</span>, model_type <span class="op">=</span> <span class="st">"bertweet"</span>, model_name <span class="op">=</span> <span class="st">"vinai/bertweet-base"</span><span class="op">)</span></span>
<span><span class="co">### If you are hardcore quanteda user:</span></span>
<span><span class="co">## model &lt;- textmodel_transformer(unciviltweets,</span></span>
<span><span class="co">##                                model_type = "bertweet", model_name = "vinai/bertweet-base")</span></span></code></pre></div>
<p>Make prediction</p>
<div class="sourceCode" id="cb6"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html" class="external-link">predict</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span></span></code></pre></div>
<p>That is it.</p>
</div>
<div class="section level2">
<h2 id="extended-examples">Extended examples<a class="anchor" aria-label="anchor" href="#extended-examples"></a>
</h2>
<p>Several extended examples are also available.</p>
<table class="table">
<colgroup>
<col width="50%">
<col width="49%">
</colgroup>
<thead><tr class="header">
<th>Examples</th>
<th>file</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>van Atteveldt et al. (2021)</td>
<td><a href="paper/vanatteveldt.html">paper/vanatteveldt.md</a></td>
</tr>
<tr class="even">
<td>Dobbrick et al. (2021)</td>
<td><a href="paper/dobbrick.html">paper/dobbrick.md</a></td>
</tr>
<tr class="odd">
<td>Theocharis et al. (2020)</td>
<td><a href="paper/theocharis.html">paper/theocharis.md</a></td>
</tr>
<tr class="even">
<td>OffensEval-TR (2020)</td>
<td><a href="paper/coltekin.html">paper/coltekin.md</a></td>
</tr>
<tr class="odd">
<td>Amharic News Text classification Dataset (2021)</td>
<td><a href="paper/azime.html">paper/azime.md</a></td>
</tr>
</tbody>
</table>
</div>
<div class="section level2">
<h2 id="some-common-choices-of-model_name">Some common choices of <code>model_name</code>
<a class="anchor" aria-label="anchor" href="#some-common-choices-of-model_name"></a>
</h2>
<table class="table">
<thead><tr class="header">
<th>Your data</th>
<th>model_type</th>
<th>model_name</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>English tweets</td>
<td>bertweet</td>
<td>vinai/bertweet-base</td>
</tr>
<tr class="even">
<td>Lightweight</td>
<td>mobilebert</td>
<td>google/mobilebert-uncased</td>
</tr>
<tr class="odd">
<td></td>
<td>distilbert</td>
<td>distilbert-base-uncased</td>
</tr>
<tr class="even">
<td>Long Text</td>
<td>longformer</td>
<td>allenai/longformer-base-4096</td>
</tr>
<tr class="odd">
<td></td>
<td>bigbird</td>
<td>google/bigbird-roberta-base</td>
</tr>
<tr class="even">
<td>English (General)</td>
<td>bert</td>
<td>bert-base-uncased</td>
</tr>
<tr class="odd">
<td></td>
<td>bert</td>
<td>bert-base-cased</td>
</tr>
<tr class="even">
<td></td>
<td>electra</td>
<td>google/electra-small-discriminator</td>
</tr>
<tr class="odd">
<td></td>
<td>roberta</td>
<td>roberta-base</td>
</tr>
<tr class="even">
<td>Multilingual</td>
<td>xlm</td>
<td>xlm-mlm-17-1280</td>
</tr>
<tr class="odd">
<td></td>
<td>xml</td>
<td>xlm-mlm-100-1280</td>
</tr>
<tr class="even">
<td></td>
<td>bert</td>
<td>bert-base-multilingual-cased</td>
</tr>
<tr class="odd">
<td></td>
<td>xlmroberta</td>
<td>xlm-roberta-base</td>
</tr>
<tr class="even">
<td></td>
<td>xlmroberta</td>
<td>xlm-roberta-large</td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section level1">
<h1 id="references">References<a class="anchor" aria-label="anchor" href="#references"></a>
</h1>
<ol style="list-style-type: decimal">
<li>Theocharis, Y., Barberá, P., Fazekas, Z., &amp; Popa, S. A. (2020). The dynamics of political incivility on Twitter. Sage Open, 10(2),
<ol start="2158244020919447" style="list-style-type: decimal"><li>
</li></ol>
</li>
<li>Nguyen, D. Q., Vu, T., &amp; Nguyen, A. T. (2020). BERTweet: A pre-trained language model for English Tweets. arXiv preprint arXiv:2005.10200.</li>
</ol>
<hr>
<ol style="list-style-type: decimal">
<li>Yes, I totally made up the meaningless long name. Actually, it is the German name of the <em>Sesame Street</em> character <a href="https://de.wikipedia.org/wiki/Sesamstra%C3%9Fe#Graf_Zahl" class="external-link">Count von Count</a>, meaning “Count (the noble title) Number”. And it seems to be so that it is compulsory to name absolutely everything related to Transformers after Seasame Street characters.</li>
</ol>
</div>

  </main><aside class="col-md-3"><div class="links">
<h2 data-toc-skip>Links</h2>
<ul class="list-unstyled">
<li><a href="https://cloud.r-project.org/package=grafzahl" class="external-link">View on CRAN</a></li>
<li><a href="https://github.com/gesistsa/grafzahl/" class="external-link">Browse source code</a></li>
<li><a href="https://github.com/gesistsa/grafzahl/issues" class="external-link">Report a bug</a></li>
</ul>
</div>

<div class="license">
<h2 data-toc-skip>License</h2>
<ul class="list-unstyled">
<li><a href="LICENSE.html">Full license</a></li>
<li><small>GPL (&gt;= 3)</small></li>
</ul>
</div>


<div class="citation">
<h2 data-toc-skip>Citation</h2>
<ul class="list-unstyled">
<li><a href="authors.html#citation">Citing grafzahl</a></li>
</ul>
</div>

<div class="developers">
<h2 data-toc-skip>Developers</h2>
<ul class="list-unstyled">
<li>
<a href="http://www.chainsawriot.com" class="external-link">Chung-hong Chan</a> <br><small class="roles"> Author, maintainer </small> <a href="https://orcid.org/0000-0002-6232-7530" target="orcid.widget" aria-label="ORCID" class="external-link"><span class="fab fa-orcid orcid" aria-hidden="true"></span></a> </li>
</ul>
</div>

<div class="dev-status">
<h2 data-toc-skip>Dev status</h2>
<ul class="list-unstyled">
<li><a href="https://CRAN.R-project.org/package=grafzahl" class="external-link"><img src="https://www.r-pkg.org/badges/version/grafzahl" alt="CRAN status"></a></li>
</ul>
</div>

  </aside>
</div>


    <footer><div class="pkgdown-footer-left">
  <p>Maintained by <a href="https://github.com/gesistsa" class="external-link"><img alt="TSA Team" src="https://raw.githubusercontent.com/gesistsa/.github/main/tsa_logo.png" width="20"> Transparent Social Analytics Team, GESIS</a></p>
</div>

<div class="pkgdown-footer-right">
  <p>Developed by <a href="http://www.chainsawriot.com" class="external-link">Chung-hong Chan</a>.</p>
</div>

    </footer>
</div>





  </body>
</html>
